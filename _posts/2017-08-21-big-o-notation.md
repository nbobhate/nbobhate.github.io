---
layout: post
title: "Oh no! It's Big O!"
published: false
tags: [Algorithms]
---

The 'Big O' notation is a function used to describe the performance of an algorithm in terms of the rate of growth of time in relation to the size of the input.

We can determine the *best case*, *average case*, and *worst case* time complexity performance of an algorithm, but we're generally most interested in the *worst case* analysis in order to better cater for it. There are certain rules that guide the determination of the Big O notation of an algorithm or method.
  - *todo*
  - *todo*
  - *todo*
  - *todo*

We can assign:
- 1 unit time for arithmetical and logical operations
- 1 unit time for assignment or return operations


Constant time algorithm : always takes the same amount of time. O(1)

Linear time algorithm : increases with the size of the data set. O(n)

Quadratic time algorithm : rate of growth is twice the data set. O(n^2)







# Resources
